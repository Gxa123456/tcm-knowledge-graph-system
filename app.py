import streamlit as st
from langchain_neo4j import Neo4jGraph, GraphCypherQAChain
from langchain_openai import ChatOpenAI

# ============ é…ç½® ============
NEO4J_URL = "bolt://localhost:7687"
NEO4J_USERNAME = "neo4j"
NEO4J_PASSWORD = "12345678"
NEO4J_DATABASE = "neo4j"

LLM_BASE_URL = "http://192.168.100.82:9080/multi_llm/v1"
LLM_MODEL = "mtm_qwen_llm"
LLM_API_KEY = "NOT_NEED"
# ====================================================================

st.set_page_config(page_title="ä¸­åŒ»çŸ¥è¯†å›¾è°±é—®ç­”", layout="wide")

@st.cache_resource
def build_chain():
    graph = Neo4jGraph(
        url=NEO4J_URL,
        username=NEO4J_USERNAME,
        password=NEO4J_PASSWORD,
        database=NEO4J_DATABASE,
        enhanced_schema=False,
        refresh_schema=False,
    )

    llm = ChatOpenAI(
        model=LLM_MODEL,
        base_url=LLM_BASE_URL,
        api_key=LLM_API_KEY,
        temperature=0,
        max_tokens=2000,
    )

    chain = GraphCypherQAChain.from_llm(
        llm=llm,
        graph=graph,
        verbose=True,
        allow_dangerous_requests=True,
    )
    return chain

st.title("ğŸ§  ä¸­åŒ»çŸ¥è¯†å›¾è°±é—®ç­”ï¼ˆNeo4j + LLMï¼‰")

with st.sidebar:
    st.subheader("è¿æ¥çŠ¶æ€")
    st.caption("å¦‚æœæŠ¥é”™ï¼Œå¤šæ•°æ˜¯ Neo4j/LLM ä¸å¯è¾¾æˆ–å¯†ç ä¸å¯¹ã€‚")
    if st.button("åˆå§‹åŒ– / é‡è¿"):
        st.cache_resource.clear()
        st.rerun()

chain = build_chain()

if "messages" not in st.session_state:
    st.session_state.messages = []

# å±•ç¤ºå†å²å¯¹è¯
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# è¾“å…¥æ¡†
question = st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼šæŸè¯å€™å¸¸è§ç—‡çŠ¶æœ‰å“ªäº›ï¼Ÿ")
if question:
    st.session_state.messages.append({"role": "user", "content": question})
    with st.chat_message("user"):
        st.markdown(question)

    with st.chat_message("assistant"):
        with st.spinner("æŸ¥è¯¢ä¸­..."):
            try:
                out = chain.invoke({"query": question})
                answer = out.get("result", str(out))
            except Exception as e:
                answer = f"âŒ å‘ç”Ÿé”™è¯¯ï¼š{e}"

        st.markdown(answer)
        st.session_state.messages.append({"role": "assistant", "content": answer})
